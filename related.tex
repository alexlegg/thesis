\chapter{Related Work}
\label{ch:relatedwork}

Reactive synthesis is an extensively studied topic and the work of this thesis is influenced by a wide array of prior work. In the previous chapter we identified symbolic representation of state sets and abstraction refinement as methodologies for mitigating state explosion. In this chapter we will approach the problem from a different angle. The work in this thesis is inspired by research in the model checking community and some prior efforts to apply that research to synthesis.

\section{Bounded model checking}

Bounded model checking~\cite{Biere99} (BMC), as introduced in Chapter~\ref{sec:boundedmodelchecking}, is a methodology that generates SAT queries to determine the existence of a trace that violates the model's specification. 

BMC considers the validity of CTL* formulas in Kripke structures in which the length of a run is bounded to $k$. The authors of the procedure provide a semantics for the translation of CTL* formulas on bounded models, via LTL, to satisfiability constraints. For example, consider a safety property $AG \phi$ where $\phi$ is a propositional formula. A safety property is universal and so is checked in BMC by searching existentially for counterexamples in the form of the negation $F \lnot \phi$. The search is translated into a SAT query by unrolling the transition relation $R$ from the initial state $s_0$ like so: $s_0 \land \bigwedge_{i=0}^{k-1} R(s_i, s_{i+1})$. The transition relation describes all valid successor states of the current state, and $k$ repeated applications of $R$ describes all valid runs of length $k$.  The LTL formula is similarly translated into a formula $\bigvee_{i=0}^{k} \lnot \phi \in L(s_i)$. The SAT query is satisfiable when there is a path of length $k$ in the Kripke structure $(s_0, s_1, ..., s_k)$ such that $\lnot \phi$ holds in some state $s_i$.

One of the motivations behind bounded model checking is aligned with the aim of this thesis: to avoid the high cost in space of approaches that construct a symbolic representation of the winning region as a binary decision diagram. By bounding the length of traces SAT can instead be used to symbolically compute reachable states of the system. The drawback is that although BMC is sound, i.e. any counterexample is a true counterexample, it is not complete with respect to the unbounded system unless a sufficient bound is used. For safety properties the diameter of the system gives a tight sufficient upper bound for BMC although it is difficult to compute.

The approach taken to realisability described in Chapter~\ref{ch:bounded} is inspired by BMC and uses a similar approach to replace BDDs with SAT queries. In my approach a bound is placed on the number of rounds in a safety game. The method of unrolling the transition relation into a SAT query is adapted to games by the addition of branching to encode a partial strategy for one player. Similar to the use of SAT to search for counterexample traces in BMC, a SAT solver is used to check for an opponent spoiling strategy.

\section{Unbounded model checking}

The usage of SAT solvers in bounded model checking proved to be highly beneficial for discovering counterexamples. Research into applications of SAT in unbounded model checking has subsequently progressed in several directions.

\subsection{Non-canonical symbolic representation}

One approach to unbounded model checking is to replace BDDs with binary expression diagrams (BEDs) or reduced boolean circuits (RBCs) in a fixed point algorithm~\cite{Williams00, Abdulla00}. BEDs are a generalisation of BDDs with the advantage that BEDs are not canonical and their use as a symbolic representation may be more succinct than the equivalent BDD. An RBC is simply a graphical representation of a circuit with some reductions applied. The two representations are essentially orthogonal and conversion between them is linear.

The disadvantage is that the image operators computed during the fixed point calculation require quantifier eliminations that increase the size of the BED or RBC. Detecting a fixed point in the state sets then requires a costly satisfiability check of combinations of the expanded formulas. One option is to construct an equivalent BDD for which the satisfiability check is efficient but this potentially negates the advantage of the non-canonical representation. It is also possible to construct a CNF representation of the formula from either a BED or RBC and query a SAT solver for satisfiability. Neither option fully mitigates the potential size of the expanded formula due to quantifier elimination. In practice this methodology works well only on models with few inputs so that quantification does not explode the formulas.

\subsection{Hybrid SAT/BDD approach}

Although many research efforts are directed away from BDDs to avoid their space blowup some work instead focuses on allowing a trade off between space and time via combinations of SAT procedures with BDDs. One such approach~\cite{Gupta00} uses BDDs to enhance SAT in two ways during a reachability fixed point algorithm.  As introduced in Chapter~\ref{ch:background}, a fixed point algorithm can be used to compute the entire set of reachable states by repeated application of the image operator.  When the set of states returned by the image operation is equivalent to the input states, i.e. the procedures encounters a fixed point, the entire set of reachable states is known.

The authors introduce a technique they call \emph{BDD bounding} to prune the search space of the SAT procedure by checking that partial assignments to a set of variables during the SAT search are contained within a BDD. An image computation requires that the assignment to current state variables is contained within the source states computed during the previous iteration. The set of source states may be represented as a BDD and BDD bounding applied to the search in order to detect and immediately backtrack when a satisfying assignment has current state variables set to a value outside the BDD.

It is possible to directly apply SAT to quantifier elimination, and thus to image computation, by repeatedly applying a SAT solver to find all satisfying solutions. This methodology applied without any optimisations is generally infeasible due to the large number of calls that must be made to the SAT solver. The authors of \cite{Gupta00} introduce a middle ground between this entirely SAT based approach and a standard BDD image computation. They suggest interrupting the SAT procedure after some partial assignment has been made to continue computation with a BDD. Effectively this is BDD image computation but distributed into smaller components by the SAT solver.

\subsection{SAT based unbounded model checking}

An optimised approach to SAT image computation is an efficient model checking procedure is cases where cube enumeration does not cause exponential blowup~\cite{McMillan02}. McMillan proposes constructing \emph{blocking clauses} by modifying the SAT procedure and analysing the solver's internal implication graph. The result is effectively cube enumeration that produces a CNF formula with intelligently enlarged cubes so that the original formula is covered in fewer SAT calls. The procedure is applied to CTL model checking by performing universal quantification on CNF formulas via variable deletion.

\subsection{Application of Craig interpolants}

Another angle of research is to extend bounded model checking into an unbounded procedure via a more efficient means than computing a diameter or other sufficient bound. In \cite{McMillan03} Craig interpolation is proposed as means of approximating the set of reachable states during bounded model checking. 

Recall the introduction of Craig interpolants in Section~\ref{sec:backgroundInterpolation}. An interpolant is a formula that may be constructed efficiently from the resolution proof of two mutually unsatisfiable formulas. It is implied by one formula and the conjunction with the second formula is unsatisfiable. During bounded model checking a formula representing an unrolling of the transition relation of length $k$ is unsatisfiable if there is no counterexample trace. This formula may be separated into an initial transition and $k-1$ remaining transitions enabling a convenient application of interpolation. An interpolant constructed this way is an overapproximation of the image computation on the initial states and the states contained in the interpolant cannot emit a counterexample in $k-1$ steps. 


\begin{algorithm}
    \begin{algorithmic}
        \Function{FiniteRun}{$I, \delta, E, k$}
            \IIf{$I \land E$} \Return \texttt{true} \EndIIf
            \State $R \gets I$
            \Loop
                \State $A \gets R(s_0) \land \delta(s_0, s_1)$
                \State $B \gets \big( \bigwedge_{1 \leq i \leq k} \delta(s_i, s_{i+1}) \big) \land \big( \bigvee_{1 \leq i \leq k}E(s_i) \big) \big)$
                \If{\Call{SAT}{$A \land B$}}\label{line:interpSatCheck}
                \State \IfElse{$R = I$}{\Return \texttt{true}}{\Call{FiniteRun}{$I, \delta, E, k+1$}} \EndIfElse
                \Else
                    \State $\mathcal{I} \gets \Call{interpolate}{A, B}$
                    \State $R' \gets \mathcal{I}(s_1)$
                    \IIf{$R' \implies R$} \Return \texttt{false} \EndIIf
                    \State $R \gets R \lor R'$
                \EndIf
            \EndLoop
        \EndFunction
    \end{algorithmic}
    \caption{FiniteRun: Determines the existence of a finite run from $I$ to $E$}
    \label{alg:interpolation}
\end{algorithm}

The algorithm (given in Algorithm~\ref{alg:interpolation}) takes a set of initial states $I \in 2^S$ where $S$ is a set of boolean state variables, a transition relation $\delta : 2^S \times 2^S$, a set of final states $E \in 2^S$, and a bound $k$. The algorithm maintains a set of states $R$ that overapproximates the reachable states from $I$. The approximation is initialised with $I$ itself and each iteration updates the approximation with the addition of an interpolant constructed in the manner described above. If it is possible to reach a final state from $I$ in $k$ steps it will be detected by the SAT query on line~\ref{line:interpSatCheck} and the algorithm returns that a finite run exists. If it is not possible to reach a final state from $I$ but it is possible from an approximation of the reachable set then a larger bound is required to determine if a run is actually possible. Otherwise, if the approximation reaches a fixed point then it forms an inductive invariant of the system and the algorithm is able to return that no run is possible.

\subsection{Properly Directed Reachability (PDR)}
\label{sec:pdr}

More recently an approach was proposed that checks safety properties without unrolling the transition relation of the system~\cite{Bradley11}. The intuition of the algorithm is to construct a proof of a safety properly $P$ by incrementally strengthening a series of inductive lemmas. This procedure provided the inspiration for the unbounded realisability algorithm of Chapter~\ref{ch:unbounded}.

The algorithm maintains a series of formulas $F_0, F_1, ..., F_k$ that overapproximate the set of states reachable in $0, 1, ..., k$ steps. The sequence is extended when $F_k(s) \land \delta(s, s') \to P'(s')$ is true indicating that $F_{k+1} = P$ is a new reachable set that maintains the safety property. Then clauses in each $F_i$ are propagated forwards to $F_{i+1}$ if it is possible to do so. When $P$ is not reachable from $F_k$ there must be a state within $F_k$ that is one step from violating the safety property. Either this state indicates a counterexample or a new relatively inductive clause can be added to some $F_i$ to prevent the state from being reachable at $F_k$. If during the forward propagation of clauses two formulas $F_i$ and $F_{i+1}$ become equivalent the algorithm has reached a fixed point and has proved that the safety property is invariant.

\section{Synthesis with SAT}

Given the success of model checking techniques employing satisfiability methods it is no surprise that many attempts have been made to replicate these results in the context of synthesis. Synthesis is a significantly more complex problem and it is not obvious how to translate the advantages of SAT, namely the ability to quickly find counterexamples, to an algorithm that must construct a model before checking it. Nonetheless advances have been made that are able to outperform BDD methods in some situations.

\subsection{Bounded Synthesis}

In Chapter~\ref{ch:bounded} we will discuss a bounded realisability algorithm. The bounded synthesis methodology introduced by \cite{Finkbeiner13} is an unfortunate conflation of terms. Their approach places a bound on the size of the implementation as opposed to bounding the length of the game as in Chapter~\ref{ch:bounded} and in bounded model checking. 

This bounded synthesis approach is used to synthesise reactive systems for distributed architectures by first constructing a universal co-B\"uchi automaton for the given LTL specification. An implementation is a transition system that drives that automaton thereby producing a run graph. The run graph of a transition system may be annotated in each node with the maximal number of rejecting states that occur on any path to that node. The authors show that the existence of an annotation with finite bounds indicates that its transition system is accepted by the automaton and hence the LTL specification. A bound is placed on the size of the transition system, which additionally sets an upper bound for the maximum label in the annotation, and an SMT solver can be used to search for a bounded transition system that has a valid annotation. In this way LTL synthesis is reduced to a series of SAT modulo integer arithmetic problems with increasing bounds.

One synthesis tool~\cite{Ehlers12} divides an LTL specification into safety and non-safety components. The safety components are solved easily by a standard symbolic algorithm with BDDs. The author proposes a symbolic version of bounded synthesis to solve the non-safety components. Their approach constructs a BDD that encodes the search for a transition system with a valid annotation. Another approach~\cite{Filiot11} similarly does symbolic bounded synthesis using antichains.

\subsection{Lazy Synthesis}

A counterexample guided framework has been applied to bounded synthesis in a methodology called lazy synthesis~\cite{Finkbeiner12}. The authors propose the construction of bounded size partial implementations via SMT solving a collection of constraints. The partial implementation is then model checked in a symbolic BDD algorithm and any counterexamples are used to introduce new constraints that refine the partial strategy. If the implementation is found to be correct during the model checking phase then the algorithm terminates. Alternatively, the constraint solver may return that there is no implementation at which point the bound on the size of the implementation is increased. 

The counterexample guided search for a correct implementation is similar to the bounded realisability approach proposed in Chapter~\ref{ch:bounded}. The framework is fundamentally the same: candidate strategies are found by a SAT solver, they are checked for correctness, and counterexamples are used to refine further searches for candidates. However, the two methodologies use different approaches to each component of that framework.

\subsection{Properly directed reachability applied to synthesis}

The incremental induction of PDR~\cite{Bradley11} (see Section~\ref{sec:pdr}) has also been applied to the realisability problem. In \cite{Morgenstern13} the authors suggest that by replacing the SAT queries used to approximate reachability with 2QBF queries that the algorithm may be used to solve realisability of safety games. 

Their approach computes overapproximations of the sets of states from which the environment can force to an error state in some number of game rounds. A state is added to the overappoximation of states that are environment winning in $k$ rounds via a 2QBF query that checks whether the environment has an action such that for all controller actions a successor state is inside the overapproximation of states winning in $k-1$ rounds. This generates new obligations for the algorithm to refine the overapproximations. Each successor state must now be checked for the ability for the environment to win in $k-1$ rounds. Eventually this process may discover a chain of states from the initial set to the error set such that the environment can force a win. Alternatively the overapproximating sets will reach a fixed point indicating that the controller can force the game to stay within a set of safe states.

The universal quantification in the 2QBF query is costly to compute so the authors propose repurposing SAT for the task. Similar to how QBFs are solved in \cite{Janota12} and in Chapter~\ref{ch:bounded}, a SAT query checks whether there is an existentially quantified pair of controller and environment actions that reaches the desired set, and another SAT query gives the controller the opportunity to revise its action. Intuitively, the first query \emph{guesses} an environment transition and the second query \emph{checks} it. To assist the process an overapproximation of controller winning states is maintained and used to direct the controller away from its losing states in the checking query. Additionally, the environment transitions that turn out to be bad guesses are learned and blocked in future attempts.

A recent approach~\cite{Chiang15} has a similar application of PDR to synthesis with the major difference being that the authors propose solving the game forwards from the initial states instead of backwards from the error set. Thus the relatively inductive sets represent overapproximations of reachable states. In the previous work the SAT query checks for environment actions that force a successor state into an approximation of environment winning states. As a result, when a transition is found to have a countering controller action it is only known to be a bad transition for the environment to force into the current target. In this more recent work the SAT query is always attempting to find transitions \emph{from} the (approximate) reachable sets into the error set. An advantage of this approach is that learned transitions may be blocked in \emph{all} future queries.

\subsection{Clause Learning for Synthesis}

In \cite{Bloem14} the authors propose a suite of learning algorithms for synthesis. Two of these algorithms are centred on learning unsafe states by solving a quantified formula that checks for environment controllable successor states outside the current approximation of the safe region. When such a state is discovered it is generalised into multiple cubes representing sets of states that are then blocked from the safe region. The specification is decided unrealisable when the initial states are no longer within the safe region and realisable when there are no states left to learn. 

The two variations of this algorithm correspond to one based on a QBF solver and one based on two competing incremental SAT solvers. The latter contains an optimisation to ensure that the incremental nature of the solvers is exploited. Incremental solvers work well in the case where new constraints are added to the problem over time. Removing constraints requires either careful backtracking of learned clauses or restarting the session with no clauses. As the safe region is restricted by blocking cubes the constraints of the solver playing on the behalf of the environment are reduced by enabling the search for transitions to outside the safe region to visit the blocked cubes. The authors suggest maintaining a separate instance of the safe region that is lazily updated. The environment searches for states with successor states outside the old version of the safe region until it is necessary to make the costly update to the incremental solver to the more permissive new safe region.

Another optimisation take inspiration from PDR to approximate reachability information during clause learning. It is not useful to learn unreachable states to remove from the safe region so the search space can be pruned by only considering an overapproximation of reachable states. The optimisation is implemented first by checking candidates for learning for inclusion in the initial set or a predecessor inside the current safe region estimate.

The authors additionally propose two approaches that attempt to directly compute a winning region. The first of these searches for assignments to the parameters of a CNF template of the winning region with a call to a QBF solver. The parameters correspond to the polarity and inclusion of variables within clauses. The second constructs an \emph{effectively propositional logic} (EPR) formula that characterises the Skolem functions encoding the winning region of the game. This cannot be solved via QBF due to the nonlinear nature of quantifiers over current and successor variables that describe the winning region. The formula can be encoded in EPR and handed to an efficient solver.

Each of these algorithms has been implemented in a tool that has the ability to run various combinations in parallel. The authors report a significant benefit to parallelisation and sharing of learned clauses in between algorithms.

\section{Quantified Boolean Formula Solving}

A quantified boolean formula (QBF) generalises the satisfiability problem to include universal and existential quantifiers (see Section~\ref{sec:backgroundQBF}). In accordance with the additional complexity of quantification QBF solvers have so far been less successful than SAT solvers at scaling to real world problems. However recent work in which competing SAT solvers are employed on behalf of each quantifier in a QBF problem have shown promising advances.

The bounded realisability problems of Chapter~\ref{ch:bounded} are specialisations of QBF problems. The algorithm proposed to solve those problems can be seen as a domain specific QBF solver. In particular, the algorithm is similar to and inspired by the general QBF algorithm of \cite{Janota12}. In this section we will review the state of the art in QBF solving in order to shed light on the advantages that an algorithm such as in Chapter~\ref{ch:bounded} has over a generalised QBF solver.

QBFs may be solved by application of DPLL~\cite{Cadoli98} or by \emph{expansion} into SAT~\cite{Ayari02} (see Section~\ref{sec:backgroundQBF}). In the former, which we refer to as \emph{search-based} approaches, computational learning can be applied to share information between separate branches of the search tree~\cite{Zhang02,Giunchiglia02}. In SAT conflicts are be remembered in order to prune the search space but once a satisfying assignment is found the solver may terminate. A QBF solver must explore satisfiability in multiple branches of the search in order to establish truth for every value to universal variables. This additional aspect to search may also be reduced by retaining \emph{cubes} of assignments that are known to lead to satisfiability.

\subsection{Q-resolution}

Q-resolution~\cite{Buning95} is a method for combining clauses and eliminating variables to eventually solve a QBF. We consider QBFs in prenex normal form with quantifiers $Q_1 \hat{x}_1 Q_2 \hat{x}_2 ... Q_n \hat{x}_n$. We assign an ordering to variables corresponding to its scope: $\hat{x}_1 < \hat{x}_2 < ... < \hat{x}_n$. We say that a formula is \emph{forall reduced} if each universally quantified literal $l$ is deleted from clauses with no existentially quantified literals of larger scope. This reduction preserves equivalence and ensures that the innermost quantifier is always existential. For example, $\forall x_1 \exists y_1 \forall x_2  ((x_1 \lor y_1 \lor x_2) \land (x_1 \lor \lnot y_1 \lor \lnot x_2))$ is equivalent to $\forall x_1 \exists y_1 ((x_1 \lor y_1) \land (x_1 \lor \lnot y_1))$.

Q-resolution is used to generate new clauses for a forall reduced QBF. Two existing clauses are selected with opposite polarities of an existentially quantified variable $y$. Taking the union of literals of both clauses, removing $y$ literals, and reapplying forall reduction produces a new clause called the \emph{resolvent}. If all possible resolvent clauses are generated for a variable $y$ it may be removed entirely from the formula along with any clause containing $y$. For example, $\forall x_1 \exists y_1 ((x_1 \lor y_1) \land (x_1 \lor \lnot y_1))$ may be further reduced to $\forall x_1 (x_1)$ by resolving on $y_1$, which after forall reduction is the empty clause and the QBF is shown to be false. 

In practice, solving a QBF with q-resolution alone will generate too many clauses to be feasible. In \cite{Biere05} an approach combining q-resolution with expansion is suggested. Resolution is used to eliminate variables from the innermost existential scope and expansion for the innermost universal scope. A scheduler selects which variable to eliminate next by selecting from all candidate variables the variable with the lowest cost. The cost of eliminating a variable is set to the upper bound of the number of literals introduced to the formula by eliminating that variable.

\subsection{Dependency graphs}

One issue with prenex normal form is that much of the structural information of the original problem is lost on conversion. The quantifier prefix can be seen as a linear variable dependency scheme. In \cite{Lonsing10}, the authors generalise variable dependency to directed acyclic graphs, which is more expressive and may more accurately represent the quantifier structure of the original problem. In a search based solver based on the extension of DPLL to QBF, variables are decided based on the partial ordering defined by the prefix. If the solver instead has access to the more general dependency graph it may have a greater degree of freedom with which to choose the order of decisions and maintain soundness.

Additionally, certain standard optimisations to the search procedure rely on dependency information for correctness. For instance a unit literal is the only unassigned existential literal $l$ in a clause in which all unassigned universal literals are independent to $l$. A unit literal constrains the variable to the polarity of the literal and so decides that variable. With a more expressive dependency scheme it is possible to detect more unit literals and speed up the search.

\subsection{Formula structure}

Structural information about a formula can be used for other optimisations to QBF. Reconstructing a circuit similar to the original problem formulation can lead to a compressed representation and more efficient quantifier elimination~\cite{Pigorsch10, Pigorsch09}. The authors propose an and-inverter graph (AIG) representation and the application of circuit compression techniques such as BDD-sweeping for compression. BDDs may also be used to do quantifier elimination in cases where the representation does not explode. Otherwise quantification is performed directly on the AIG by symbolically expanding the circuit followed by compression.

Circuits may also be used as a representation of the problem in a search-based QBF solver~\cite{Goultiaeva09}. The advantages in this setting include propagation of assignments both forwards and backwards as well as identification of irrelevant \emph{don't care} literals by analysing the gates of a circuit. This technique was further improved by the introduction of ghost literals~\cite{Klieber10}, which enables the solver to propagate cubes of learned satisfying assignments in the same way that learned constraints are.

\subsection{SAT for QBF}

SAT solvers are very efficient at finding satisfying assignment to existential queries but less efficient at proving unsatisfiability or, equivalently, satisfiability of universal queries. This asymmetry has been recognised and turned to an advantage in QBF solvers that use SAT to discover counterexamples to the universal component of QBF problems.

Counterexamples may be used to guide the careful expansion of a QBF~\cite{Janota15} into a propositional formula. This algorithm provides the inspiration for the domain specific QBF solver in \ref{ch:bounded}. The QBF is viewed as a game between an existential player and a universal player in which the existential player attempts to satisfy the formula and the universal player seeks to falsify it. The algorithm solves the game recursively by construction an abstraction, finding a candidate solution for one player under that abstraction, and subsequently verifying that candidate in the concrete game. The game is abstracted by partially expanding the QBF into propositional logic. A subset of possible assignments at each quantifier level are expanded into a disjunction for existential levels or conjunction for universal levels. If the current player cannot win in the abstraction against a restricted opponent then it cannot win in the concrete game so the abstraction can be used to find a candidate valuation to the player's current level variables with an efficient SAT call. The candidate is then checked by recursively calling the solver on the suffix of the formula. This effectively replaces the current player's choice with its candidate selection and hands control to the opponent. If the recursive call discovers a counterexample it is added to the abstraction and a new candidate is found. If there is no counterexample then the current player wins. If the refined abstraction now allows no candidate solution then the opponent wins. The full algorithm is listed in Algorithm~\ref{alg:rareqs}.

\begin{algorithm}
    \begin{algorithmic}[1]
        \Function{solve}{$QX(\varphi)$}
        \If{$\varphi$ has no quantifiers}
            \State \Return $(Q = \exists)$ ? \Call{SAT}{$\varphi$} : \Call{SAT}{$\lnot\varphi$}
        \EndIf
        \State $\omega \gets \emptyset$
        \Loop
        \State $\alpha \gets (Q = \exists)$ ? $\bigwedge_{\mu \in \omega} \varphi[\mu]$ : $\bigvee_{\mu \in \omega} \varphi[\mu]$
        \State $\tau' \gets$ \Call{solve}{\Call{prenex}{$QX(\alpha)$}}
        \IIf{$\tau' = \texttt{NULL}$} \Return $\texttt{NULL}$ \EndIIf
        \State $\tau \gets \{ l\ |\ l \in \tau' \land \texttt{var}(l) \in X \}$
        \State $\mu \gets $ \Call{solve}{$\varphi[\tau]$}
        \IIf{$\mu = \texttt{NULL}$} \Return $\tau$ \EndIIf
        \State $\omega \gets \omega \cup \{ \mu \}$
        \EndLoop
        \EndFunction
    \end{algorithmic}
    \caption{Counterexample guided QBF}
    \label{alg:rareqs}
\end{algorithm}

Two recent counterexample guided approaches work on the idea of abstracting the QBF via the selection of a subset of clauses~\cite{Rabe15,Janota15}. In both works the authors suggest that competing SAT solvers select a subset of clauses for the opposing solver to satisfy at each quantifier alternation. In \cite{Janota12} the QBF abstraction is refined via expansion and may lead to an exponential increase in the size of the formula. By instead linearly increasing the formula to include selection variables enabling an abstraction over clauses the more recent approaches avoid that potential explosion.

An orthogonal approach uses nested SAT solvers to solve formulas of the form $\exists \sigma (\varphi \land (\lnot \exists \tau (\psi)))$ where $\varphi$ is a CNF, $\psi$ is a QBF~\cite{Bogaerts16}. At each quantifier level an underapproximation of $\psi$ is given to a recursive solver while the CNF portion is solved via SAT. The SAT solver hands partial assignments gathered by propagating assignments through $\varphi$ to the nested solvers. The partial assignment is validated on the underapproximation in order to discover conflicts from further inside the QBF. 

\section{Summary}

The bounded realisability algorithm presented in this thesis can be seen as an extension of bounded model checking techniques into synthesis. Bounded realisability replaces the SAT calls in bounded model checking with QBF queries. 
In Chapter~\ref{ch:bounded} I present a domain specific QBF algorithm that solves these queries more efficiently than a generalised QBF solver. In Chaper~\ref{ch:strategy} and Chapter~\ref{ch:unbounded} I present extensions of the bounded realisability algorithm to synthesis and to unbounded games respectively. The approaches of those chapters are similar to existing extensions of bounded model checking into unbounded model checking. In this chapter we reviewed the literature on both bounded and unbounded model checking and the state of the art in QBF solving in order to show the inspirations for the work in this thesis.

This chapter also presented methodologies with a similar aim of applying the efficiency of SAT solving to synthesis. In the following chapters I will present my approach and defer a thorough comparison to the related methodologies until then.
