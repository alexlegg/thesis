\chapter{Related Work}
\label{ch:relatedwork}

Reactive synthesis is an extensively studied topic and the work of this thesis is influenced by a wide array of prior work. In the previous chapter we identified symbolic representation of state sets and abstraction refinement as methodologies for mitigating state explosion. In this chapter we will approach the problem from a different angle. The work in this thesis is inspired by research in the model checking community and some prior efforts to apply that research to synthesis.

\section{Bounded model checking}

Bounded model checking~\cite{Biere99} (BMC), as introduced in Chapter~\ref{sec:boundedmodelchecking}, is a methodology that generates SAT queries to determine the existence of a trace in a game that violates its specification. The approach taken to realisability described in Chapter~\ref{ch:bounded} is inspired by BMC and also unrolls the transition relationship into a SAT query and searches for counterexample traces. 

BMC considers the validity of CTL* formulas in Kripke structures in which the game is bounded to $k$ rounds. The authors of the procedure provide a semantics for the translation of CTL* formulas on bounded models, via LTL, to satisfiability constraints. Consider a safety property $AG \phi$ as an example. A safety property is universal and so is checked in BMC by searching existentially for counterexamples in the form of the negation $F \lnot \phi$. The search is translated into a SAT query by unrolling the transition relation $R$ like so: $s_0 \land \bigwedge_{i=0}^{k-1} R(s_i, s_{i+1})$. The LTL formula is similarly translated into a formula $\bigvee_{i=0}^{k} \lnot \phi \in L(s_i)$. The SAT query is equivalent to a check whether there is a path in the bounded Kripke structure $(s_0, s_1, ..., s_k)$ such that $\lnot \phi$ holds in some state $s_i$.

For bounded realisability, the unrolling of the transition relation and the translation of the safety property can be done in much the same way. The difference is that in a synthesis problem the model has yet to be constructed and the algorithm must be given the freedom to choose the actions of the controller. For more details about how this can be overcome, see Chapter~\ref{ch:bounded}.

One of the motivations behind bounded model checking is aligned with the aim of this thesis: to avoid the high cost in space of approaches that construct a symbolic representation of the winning region as a binary decision diagram. By bounding the length the game the procedure can rely on SAT as a symbolic representation instead of BDDs. The drawback is that although BMC is sound, any counterexample is a true counterexample, it is not complete with respect to the unbounded game unless a sufficient bound is used. For safety properties the diameter of the game gives a tight sufficient upper bound for BMC although it is difficult to compute. Due to the additional complexity of synthesis it is not feasible to use the diameter in a bounded synthesis procedure.

\section{Unbounded model checking}

The usage of SAT solvers in bounded model checking proved to be highly beneficial for discovering counterexamples. Research into applications of SAT in unbounded model checking has subsequently progressed in several directions.

\subsection{Non-canonical symbolic representation}

One approach to unbounded model checking is to replace BDDs with binary expression diagrams (BEDs) or reduced boolean circuits (RBCs) in a fixed point algorithm~\cite{Williams00, Abdulla00}. BEDs are a generalisation of BDDS with the advantage that BEDs are not canonical and their use as a symbolic representation may be more succinct than the equivalent BDD. An RBC is simply a graphical representation of a circuit with some reductions applied. The two representations are essentially orthogonal and conversion between them is linear.

The disadvantage is that the controllable predecessor computations during the fixed point calculation require quantifier elimination that increase the size of the BED or RBC. Detecting a fixed point in the state sets then requires a costly satisfiability check of combinations of the expanded formulas. One option is to construct an equivalent BDD for which the satisfiability check is efficient but potentially negates the advantage of the non-canonical representation. It is also possible to construct a CNF representation of the formula from either a BED or RBC and query a SAT solver for satisfiability. Neither option fully mitigates the potential size of the expanded formula due to quantifier elimination. In practice this methodology works well only on models with few inputs so that quantification does not explode the formulas.

\subsection{Hybrid SAT/BDD approach}

Although many research efforts are directed away from BDDs to avoid their space blowup some work instead focuses on allowing a trade off between space and time via combinations of SAT procedures with BDDs. One such approach~\cite{Gupta00} uses BDDs to enhance SAT in two ways during a reachability fixed point algorithm.In Chapter~\ref{ch:background} a fixed point algorithm for solving safety games using the uncontrollable predecessor backwards from the error set was introduced. The authors of this work solve the dual game, reachability, in a forwards direction by iteratively computing the \emph{image} of the initial states. The image operator takes a set of source states and returns the states that one player can force the game to. This is the forward searching version of the uncontrollable predecessor, which is also sometimes called a \emph{preimage}.

The authors introduce a technique they call \emph{BDD bounding} to prune the search space of the SAT procedure by checking that partial assignments to a set of variables during the SAT search are contained within a BDD. An image computation requires that the assignment to current state variables is contained within the source states computed during the previous iteration. The set of source states may be represented as a BDD and BDD bounding applied to the search in order to detect and immediately backtrack when a satisfying assignment has current state variables set to a value outside the BDD.

It is possible to directly apply SAT to quantifier elimination, and thus to image computation, by repeatedly applying a SAT solver to find all satisfying solutions. This methodology applied without any optimisations is generally infeasible due to the large number of calls that must be made to the SAT solver. The authors of \cite{Gupta00} introduce a middle ground between this entirely SAT based approach and a standard BDD image computation. They suggest interrupting the SAT procedure after some partial assignment has been made to continue computation with a BDD. Effectively this is BDD image computation but distributed into smaller components by the SAT solver.

\subsection{SAT based unbounded model checking}

An optimised approach to SAT image computation is an efficient model checking procedure is cases where cube enumeration does not cause exponential blowup~\cite{McMillan02}. McMillan proposes constructing \emph{blocking clauses} by modifying the SAT procedure and analysing the solver's internal implication graph. The result is effectively cube enumeration that produces a CNF formula with intelligently enlarged cubes so that the original formula is covered in fewer SAT calls. The procedure is applied to CTL model checking by performing universal quantification on CNF formulas via variable deletion.

\subsection{Application of Craig interpolants}

Another angle of research is to extend bounded model checking into an unbounded procedure via a more efficient means than computing a diameter or other sufficient bound. In \cite{McMillan03} Craig interpolation is proposed as means of approximating the set of reachable states during bounded model checking. 

Recall the introduction of Craig interpolants in Section~\ref{sec:backgroundInterpolation}. An interpolant is a formula that may be constructed efficiently from the resolution proof of two mutually unsatisfiable formulas. It is implied by one formula and the conjunction with the second formula is unsatisfiable. During bounded model checking a formula representing an unrolling of the transition relation of length $k$ is unsatisfiable if there is no counterexample trace. This formula may be separated into an initial game round and $k-1$ remaining game rounds enabling a convenient application of interpolation. An interpolant constructed this way is an overapproximation of the image computation on the initial states and the states contained in the interpolant cannot emit a counterexample in $k-1$ game rounds.

This process is applied iteratively by setting the starting point of the unrolled formula to the union of the initial states and any previously computed interpolants. By construction via interpolants no state inside this set enables a counterexample run. Eventually this set will either reach a fixed point and provide an inductive invariant of the system, indicating that the specification of the model holds in the unbounded game, or a counterexample run will be found.

\subsection{Properly Directed Reachability (PDR)}
\label{sec:pdr}

More recently an approach was proposed that solves safety games without unrolling the transition relation of the game~\cite{Bradley11}. The intuition of the algorithm is to construct a proof of a safety properly $P$ by incrementally strengthening a series of inductive lemmas. This procedure provided the inspiration for the unbounded realisability algorithm of Chapter~\ref{ch:unbounded}.

The algorithm maintains a series of formulas $F_0, F_1, ..., F_k$ that overapproximate the set of states reachable in $0, 1, ..., k$ game rounds. The sequence is extended when $F_k \land T \to P'$ is true indicating that $F_{k+1} = P$ is a new reachable set that maintains the safety property. Then clauses in each $F_i$ are propagated forwards to $F_{i+1}$ if it is possible to do so. When $P$ is not reachable from $F_k$ there must be a state within $F_k$ that is one step from violating the safety property. Either this state indicates a counterexample or a new relatively inductive clause can be added to some $F_i$ to prevent the state from being reachable at $F_k$. If during the forward propagation of clauses two formulas $F_i$ and $F_{i+1}$ become equivalent the algorithm has reached a fixed point and has proved that the safety property is invariant.

\section{Synthesis with SAT}

Given the success of model checking techniques employing satisfiability methods it is no surprise that many attempts have been made to replicate these results in the context of synthesis. Synthesis is a significantly more complex problem and it is not obvious how to translate the advantages of SAT, namely the ability to quickly find counterexamples, to an algorithm that must construct a model before checking it. Nonetheless advances have been made that are able to outperform BDD methods in some situations.

\subsection{Bounded Synthesis}

In Chapter~\ref{ch:bounded} we will discuss a bounded realisability algorithm. The bounded synthesis methodology introduced by \cite{Finkbeiner13} is an unfortunate conflation of terms. Their approach places a bound on the size of the implementation as opposed to bounding the length of the game as in Chapter~\ref{ch:bounded} and in bounded model checking. 

This bounded synthesis approach is used to synthesise reactive systems for distributed architectures by first constructing a universal co-B\"uchi automaton for the given LTL specification. An implementation is a transition system that drives that automaton thereby producing a run graph. The run graph of a transition system may be annotated in each node with the maximal number of rejecting states that occur on any path to that node. The authors show that the existence of an annotation with finite bounds indicates that its transition system is accepted by the automaton and hence the LTL specification. A bound is placed on the size of the transition system, which additionally sets an upper bound for the maximum label in the annotation, and an SMT solver can be used to search for a bounded transition system that has a valid annotation. In this way LTL synthesis is reduced to a series of SAT modulo integer arithmetic problems with increasing bounds.

One synthesis tool~\cite{Ehlers12} divides an LTL specification into safety and non-safety components. The safety components are solved easily by a standard symbolic algorithm with BDDs. The author proposes a symbolic version of bounded synthesis to solve the non-safety components. Their approach constructs a BDD that encodes the search for a transition system with a valid annotation. Another approach~\cite{Filiot11} similarly does symbolic bounded synthesis using antichains.

\subsection{Lazy Synthesis}

A counterexample guided framework has been applied to bounded synthesis in a methodology called lazy synthesis~\cite{Finkbeiner12}. The authors propose the construction of bounded size partial implementations via SMT solving a collection of constraints. The partial implementation is then model checked in a symbolic BDD algorithm and any counterexamples are used to introduce new constraints that refine the partial strategy. If the implementation is found to be correct during the model checking phase then the algorithm terminates. Alternatively, the constraint solver may return that there is no implementation at which point the bound on the size of the implementation is increased. 

The counterexample guided search for a correct implementation is similar to the bounded realisability approach proposed in Chapter~\ref{ch:bounded}. The framework is fundamentally the same: candidate strategies are found by a SAT solver, they are checked for correctness, and counterexamples are used to refine further searches for candidates. However, the two methodologies use different approaches to each component of that framework.

\subsection{Properly directed reachability applied to synthesis}

The incremental induction of PDR~\cite{Bradley11} (see Section~\ref{sec:pdr}) has also been applied to the realisability problem. In \cite{Morgenstern13} the authors suggest that by replacing the SAT queries used to approximate reachability with 2QBF queries that the algorithm may be used to solve realisability of safety games. 

Their approach computes overapproximations of the sets of states from which the environment can force to an error state in some number of game rounds. A state is added to the overappoximation of states that are environment winning in $k$ rounds via a 2QBF query that checks whether the environment has an action such that for all controller actions a successor state is inside the overapproximation of states winning in $k-1$ rounds. This generates new obligations for the algorithm to refine the overapproximations. Each successor state must now be checked for the ability for the environment to win in $k-1$ rounds. Eventually this process may discover a chain of states from the initial set to the error set such that the environment can force a win. Alternatively the overapproximating sets will reach a fixed point indicating that the controller can force the game to stay within a set of safe states.

The universal quantification in the 2QBF query is costly to compute so the authors propose repurposing SAT for the task. Similar to how QBFs are solved in \cite{Janota12} and in Chapter~\ref{ch:bounded}, a SAT query checks whether there is an existentially quantified pair of controller and environment actions that reaches the desired set, and another SAT query gives the controller the opportunity to revise its action. Intuitively, the first query \emph{guesses} an environment transition and the second query \emph{checks} it. To assist the process an overapproximation of controller winning states is maintained and used to direct the controller away from its losing states in the checking query. Additionally, the environment transitions that turn out to be bad guesses are learned and blocked in future attempts.

A recent approach~\cite{Chiang15} has a similar application of PDR to synthesis with the major difference being that the authors propose solving the game forwards from the initial states instead of backwards from the error set. Thus the relatively inductive sets represent overapproximations of reachable states. In the previous work the SAT query checks for environment actions that force a successor state into an approximation of environment winning states. As a result, when a transition is found to have a countering controller action it is only known to be a bad transition for the environment to force into the current target. In this more recent work the SAT query is always attempting to find transitions \emph{from} the (approximate) reachable sets into the error set. An advantage of this approach is that learned transitions may be blocked in \emph{all} future queries.

\subsection{Clause Learning for Synthesis}

In \cite{Bloem14} the authors propose a suite of learning algorithms for synthesis. Two of these algorithms are centred on learning unsafe states by solving a quantified formula that checks for environment controllable successor states outside the current approximation of the safe region. When such a state is discovered it is generalised into multiple cubes representing sets of states that are then blocked from the safe region. The specification is decided unrealisable when the initial states are no longer within the safe region and realisable when there are no states left to learn. 

The two variations of this algorithm correspond to one based on a QBF solver and one based on two competing incremental SAT solvers. The latter contains an optimisation to ensure that the incremental nature of the solvers is exploited. Incremental solvers work well in the case where new constraints are added to the problem over time. Removing constraints requires either careful backtracking of learned clauses or restarting the session with no clauses. As the safe region is restricted by blocking cubes the constraints of the solver playing on the behalf of the environment are reduced by enabling the search for transitions to outside the safe region to visit the blocked cubes. The authors suggest maintaining a separate instance of the safe region that is lazily updated. The environment searches for states with successor states outside the old version of the safe region until it is necessary to make the costly update to the incremental solver to the more permissive new safe region.

Another optimisation take inspiration from PDR to approximate reachability information during clause learning. It is not useful to learn unreachable states to remove from the safe region so the search space can be pruned by only considering an overapproximation of reachable states. The optimisation is implemented first by checking candidates for learning for inclusion in the initial set or a predecessor inside the current safe region estimate.

The authors additionally propose two approaches that attempt to directly compute a winning region. The first of these searches for assignments to the parameters of a CNF template of the winning region with a call to a QBF solver. The parameters correspond to the polarity and inclusion of variables within clauses. The second constructs an \emph{effectively propositional logic} (EPR) formula that characterises the Skolem functions encoding the winning region of the game. This cannot be solved via QBF due to the nonlinear nature of quantifiers over current and successor variables that describe the winning region. The formula can be encoded in EPR and handed to an efficient solver.

Each of these algorithms has been implemented in a tool that has the ability to run various combinations in parallel. The authors report a significant benefit to parallelisation and sharing of learned clauses in between algorithms.

\section{Quantified Boolean Formula Solving}

A quantified boolean formula (QBF) generalises the satisfiability problem to include universal and existential quantifiers. In accordance with the additional complexity of quantification QBF solvers have so far been less successful than SAT solvers at scaling to real world problems. However recent work in which competing SAT solvers are employed on behalf of each quantifier in a QBF problem have shown promising advances.

The bounded realisability problems of Chapter~\ref{ch:bounded} are specialisations of QBF problems. The algorithm proposed to solve those problems can be seen as a domain specific QBF solver. In particular, the algorithm is similar to and inspired by the general QBF algorithm of \cite{Janota12}. In this section we will review the state of the art in QBF solving in order to shed light on the advantages that an algorithm such as in Chapter~\ref{ch:bounded} has over a generalised QBF solver.

QBFs may be solved by application of DPLL~\cite{Cadoli98} or by \emph{expansion} into SAT~\cite{Ayari02} (see Section~\ref{sec:backgroundQBF}). In the former, which we refer to as \emph{search-based} approaches, computational learning can be applied to share information between separate branches of the search tree~\cite{Zhang02,Giunchiglia02}. In SAT conflicts are be remembered in order to prune the search space but once a satisfying assignment is found the solver may terminate. A QBF solver must explore satisfiability in multiple branches of the search in order to establish truth for every value to universal variables. This additional aspect to search may also be reduced by retaining \emph{cubes} of assignments that are known to lead to satisfiability.

\subsection{Q-resolution}

Q-resolution~\cite{Buning95} is a method for combining clauses and eliminating variables to eventually solve a QBF. We consider QBFs in prenex normal form with quantifiers $Q_1 \hat{x}_1 Q_2 \hat{x}_2 ... Q_n \hat{x}_n$. We assign an ordering to variables corresponding to its scope: $\hat{x}_1 < \hat{x}_2 < ... < \hat{x}_n$. We say that a formula is \emph{forall reduced} if each universally quantified literal $l$ is deleted from clauses with no existentially quantified literals of larger scope. This reduction preserves equivalence and ensures that the innermost quantifier is always existential. For example, $\forall x_1 \exists y_1 \forall x_2  ((x_1 \lor y_1 \lor x_2) \land (x_1 \lor \lnot y_1 \lor \lnot x_2))$ is equivalent to $\forall x_1 \exists y_1 ((x_1 \lor y_1) \land (x_1 \lor \lnot y_1))$.

Q-resolution is used to generate new clauses for a forall reduced QBF. Two existing clauses are selected with opposite polarities of an existentially quantified variable $y$. Taking the union of literals of both clauses, removing $y$ literals, and reapplying forall reduction produces a new clause called the \emph{resolvent}. If all possible resolvent clauses are generated for a variable $y$ it may be removed entirely from the formula along with any clause containing $y$. For example, $\forall x_1 \exists y_1 ((x_1 \lor y_1) \land (x_1 \lor \lnot y_1))$ may be further reduced to $\forall x_1 (x_1)$ by resolving on $y_1$, which after forall reduction is the empty clause and the QBF is shown to be false. 

In practice, solving a QBF with q-resolution alone will generate too many clauses to be feasible. In \cite{Biere05} an approach combining q-resolution with expansion is suggested. Resolution is used to eliminate variables from the innermost existential scope and expansion for the innermost universal scope. A scheduler selects which variable to eliminate next by selecting from all candidate variables the variable with the lowest cost. The cost of eliminating a variable is set to the upper bound of the number of literals introduced to the formula by eliminating that variable.

\subsection{Dependency graphs}

One issue with prenex normal form is that much of the structural information of the original problem is lost on conversion. The quantifier prefix can be seen as a linear variable dependency scheme. In \cite{Lonsing10}, the authors generalise variable dependency to directed acyclic graphs, which is more expressive and may more accurately represent the quantifier structure of the original problem. In a search based solver based on the extension of DPLL to QBF, variables are decided based on the partial ordering defined by the prefix. If the solver instead has access to the more general dependency graph it may have a greater degree of freedom with which to choose the order of decisions and maintain soundness.

Additionally, certain standard optimisations to the search procedure rely on dependency information for correctness. For instance a unit literal is the only unassigned existential literal $l$ in a clause in which all unassigned universal literals are independent to $l$. A unit literal constrains the variable to the polarity of the literal and so decides that variable. With a more expressive dependency scheme it is possible to detect more unit literals and speed up the search.

\subsection{Formula structure}

Structural information about a formula can be used for other optimisations to QBF. Reconstructing a circuit similar to the original problem formulation can lead to a compressed representation and more efficient quantifier elimination~\cite{Pigorsch10, Pigorsch09}. The authors propose an and-inverter graph (AIG) representation and the application of circuit compression techniques such as BDD-sweeping for compression. BDDs may also be used to do quantifier elimination in cases where the representation does not explode. Otherwise quantification is performed directly on the AIG by symbolically expanding the circuit followed by compression.

Circuits may also be used as a representation of the problem in a search-based QBF solver~\cite{Goultiaeva09}. The advantages in this setting include propagation of assignments both forwards and backwards as well as identification of irrelevant \emph{don't care} literals.

GhostQ

\subsection{SAT for QBF}

SAT-To-SAT

Rareqs

\subsection{}

CADET and Caqe
