\chapter{Background}
\label{ch:background}

Synthesis is a process that demands mathematical formalisation in order to
provide a strong guarantee of the correctness of the resultant software. As
such we require a mathematical language to describe the system we wish to
produce, the environment in which it operates, and the properties we want the
system to adhere to. This chapter will outline that language and the ways we
can reason about what we describe in it.

\section{Temporal Logic}

In this thesis we are concerned with reactive systems. Traditional programs can be verified by checking that the output is correct for each possible input. In a reactive system, i.e. a system that is in a continuous state of interaction with its environment, there is no termination and therefore no final output to verify. Instead the system is considered correct if it adheres to its specification indefinitely. A formalism of a reactive system must then consider the concept of time in order to specify its correctness property. 

In this thesis, device drivers will be frequently used as an example of a reactive system. A driver accepts requests from the operating system and information about internal state from the device, and it responds by sending commands to the device and reporting to the operating system. The correctness of a device driver might be specified by a statement in temporal logic that corresponds to something similar to \emph{the driver does not enter an error state} or \emph{the driver always responds to requests}. In the following sections the syntax and semantics required to make such statements formal will be introduced.

\subsection{Kripke Structures}

A reactive system can be thought of as a sequence of \emph{states}. The system
\emph{transitions} between these states as it responds to its inputs. A Kripke
structure~\cite{Kripke63} formalises this notion and provides us will the
language to reason about a reactive system.

A Kripe structure $M$ is defined by the tuple $M = (S, S_0, R, L)$ with respect
to a set of atomic propositions $AP$.

\begin{itemize}
    \item A finite set of states, $S$,
    \item a subset of initial stats $S_0 \subseteq S$,
    \item a transition relation $R \subseteq S \times S$, and
    \item a labelling function $L : S \to 2^{AP}$.
\end{itemize}

The transition relation defines how the system moves between states. It must be
left-total, i.e. for every $s \in S$ there is an $s' \in S$ s.t. $R(s, s')$.
The labelling function maps every state in $S$ to a set of atomic propositions
that hold in that state of the system.

We often consider \emph{paths} or \emph{runs} of a Kripke structure. A path is
a sequence of states $\pi = s_0, s_1, s_2, ...$ such that $R(s_i, s_{i+1})$
holds for all $i \geq 0$.

\subsection{Linear Temporal Logic}

Kripke structures lay the groundwork for reasoning about reactive systems. Using the labelling function we may define desirable properties for the system that must hold in particular states. What is now lacking is a means of bringing states together to express properties of the system as a whole. This requires a logical language that can express temporal properties.

Temporal logic takes propositional logic and provides additional semantics for
the concept of time. In a Kripke structure this refers to the expressiveness to
reason about runs of the system. This allows us to define properties that must
be true for the entire execution of a reactive system.

Linear temporal logic (LTL) allows for statements that refer to a single run of
a Kripke structure. Pnueli introduced LTL in 1977~\cite{Pnueli77} to succinctly
describe the outcomes of program execution by referring to global invariants
and eventualities. The syntax is:

\begin{itemize}
    \item $\phi$ is a propositional formula referring to the current state,
    \item $X\phi$ - $\phi$ is true in the next state of the execution,
    \item $F\phi$ - Eventually (finally) $\phi$ will be true, and
    \item $G\phi$ - $\phi$ is always (globally) true.
    \item $\phi_1 U \phi_2$ - $\phi_1$ holds until $\phi_2$ holds.
\end{itemize}

These operators are semantically defined with respect to a Kripke structure $M
= (S, S_0, R, L)$. We use $M, s \models \phi$ to denote $\phi$ holds true at
state $s \in S$ of structure $M$. We definte $\models$ recursively:

\begin{itemize}
    \item $M, s \models \phi$ iff $\phi \in L(s)$.
    \item $M, s \models \lnot\phi$ iff not $(M, s \models \phi)$.
    \item $M, s \models \phi_1 \land \phi_2$ iff $(M, s \models \phi_1) \land (M, s \models \phi_2)$.
    \item $M, s \models \phi_1 \lor \phi_2$ iff $(M, s \models \phi_1) \lor (M, s \models \phi_2)$.
    \item $M, s \models X\phi$ iff for some state $s'$, $R(s, s') \land M, s' \models \phi$.
    \item $M, s_0 \models F\phi$ iff for some path $(s_0, s_1, ...)$, $\exists i (i \geq 0 \land (M, s_i \models \phi))$.
    \item $M, s_0 \models G\phi$ iff for some path $(s_0, s_1, ...)$, $\forall i (i \geq 0 \land (M, s_i \models \phi))$.
    \item $M, s_0 \models \phi_1 U \phi_2$ iff for some path $(s_0, s_1, ...)$, $\exists i (i \geq 0 \land (M, s_i \models \phi_2) \land \forall j (j \geq 0 \land g < i \to (M, s_j \models \phi_1)))$.
\end{itemize}

Throughout this thesis we use $F$ and $G$ to represent the \emph{finally} and \emph{globally} operators. Elsewhere in the literature $\lozenge$ and $\square$ are sometimes used to represent the same.  

\subsection{Computation Tree Logic}

In addition to LTL, which is used to formalise properties about a single
execution trace, we may need the ability to talk about aggregations of traces.
In 1981 Clarke introduced computation tree logic (CTL)~\cite{Clarke81}, which
has additional syntax and semantics for exactly that. The syntax of CTL is as
follows:

\begin{itemize}
    \item $A\phi$ - $\phi$ is true on all paths
    \item $E\phi$ - there exists a path on which $p$ is true
\end{itemize}

We again define the semantics of CTL with respect to a Kripke structure $M =
(S, S_0, R, L)$.

\begin{itemize}
    \item $M, s \models \phi$ iff $\phi \in L(s)$.
    \item $M, s \models \lnot\phi$ iff $\lnot (M, s \models \phi)$.
    \item $M, s \models \phi_1 \land \phi_2$ iff $(M, s \models \phi_1) \land (M, s \models \phi_2)$.
    \item $M, s \models \phi_1 \lor \phi_2$ iff $(M, s \models \phi_1) \lor (M, s \models \phi_2)$.
    \item $M, s \models EX\phi$ iff for some state $s'$, $R(s, s') \land M, s' \models \phi$.
    \item $M, s \models AX\phi$ iff for all states $s'$, $R(s, s') \to M, s' \models \phi$.
    \item $M, s_0 \models A[\phi_1 U \phi_2]$ iff for all paths $(s_0, s_1, ...)$, $\exists i (i \geq 0 \land (M, s_i \models \phi_2) \land \forall j (j \geq 0 \land g < i \to (M, s_j \models \phi_1)))$.
    \item $M, s_0 \models E[\phi_1 U \phi_2]$ iff for some path $(s_0, s_1, ...)$, $\exists i (i \geq 0 \land (M, s_i \models \phi_2) \land \forall j (j \geq 0 \land g < i \to (M, s_j \models \phi_1)))$.
    \item $(M, s \models AF\phi) \Leftrightarrow (M, s \models A[\top U \phi])$
    \item $(M, s \models EF\phi) \Leftrightarrow (M, s \models E[\top U \phi])$
    \item $(M, s \models AG\phi) \Leftrightarrow (M, s \models \lnot EF (\lnot \phi))$
    \item $(M, s \models EG\phi) \Leftrightarrow (M, s \models \lnot AF (\lnot \phi))$
%%%    \item $M, s_0 \models AG\phi$ iff For all paths $(s_0, s_1, ...)$, $\forall i (i \geq 0 \land (M, s_i \models \phi))$.
\end{itemize}

In CTL, each $A$ or $E$ must be paired with an LTL operator. For example
$AG\phi$, which says that $\phi$ must always hold on all paths. Alternatively,
CTL* allows for free mixing of operators from LTL and CTL. This allows for
terms such as $E(GF\phi)$, which is true iff there exists a path where $\phi$
will always be true at some future state. There is also ACTL*, which is CTL* with no existential branch quantifier.

\section{Model Checking}

Before turning our attention to the synthesis of a program that is correct according to its temporal logic specification let us consider the simpler problem of verifying that an existing program is correct. Verification can be done by manually constructing a proof of correctness but this is labour intensive process even with the assistance of a mechanised proof assistant. Here we consider \emph{model checking}, which is the problem of automatically verifying the system.

The first such automatic model checker was proposed by Clarke et al.~\cite{Clarke86} to verify temporal properties of finite state programs. The algorithm they proposed was a search based labelling of a finite state transition graph, representing the program, with subformulas of the temporal logic specification. 

Another approach is based on the notion that temporal logic properties can be
expressed in terms of automata theory. Specifically, a finite state automaton
over infinite words can be used to represent a temporal logic formula. B\"uchi
automata~\cite{Buchi62} are $\omega$-automata, i.e. finite automata that accept
an infinite stream of input, which may be constructed such that the automaton
will accept exactly the inputs allowable by a temporal logic formula.

In \cite{Vardi96}, the authors propose a model checking approach using this
connection between temporal logic and automata theory. They propose the
construction of a finite state, infinite word generator representing the
program $P$, and an acceptor of the same, $\phi$, constructed from the temporal
property to be checked. Thus the program may be checked by determining whether $P \cap \lnot \phi$ is empty.


In Section~\ref{sec:boundedmodelchecking} another approach to model checking is discussed that searches for counterexamples to safety properties using a SAT solver.

\subsection{B\"uchi Automata}

Like all $\omega$-automata, the language of a B\"uchi automaton is
$\omega$-regular, i.e. a regular language extended to infinite streams. A
regular language over the alphabet $\Sigma$ is

\begin{itemize}
    \item The empty language $\empty$, \emph{or}
    \item A singleton language $\{a\}$ for $a \in \Sigma$, \emph{or}
    \item For two regular languages $A$ and $B$:
    \begin{itemize}
        \item $A \cup B$ the union of those languages, \emph{or}
        \item $A \centerdot B$ the concatenation of those languages, \emph{or}
        \item $A*$ the Kleene operation on that language.
    \end{itemize}
\end{itemize}

The automaton itself is defined as a tuple $A = (Q, \Sigma, \delta, q_0, F)$ where

\begin{itemize} 
    \item $Q$ is a finite set of states,
    \item $\Sigma$ is a finite alphabet,
    \item $\delta : Q \times \Sigma \to Q$ is a transition function mapping states and letters to next states,
    \item $q_0 \in Q$ is an initial state, and
    \item $F \subseteq Q$ is a set of accepting states. $A$ accepts an input stream iff it visits $F$ infinitely often.
\end{itemize}

Rabin automata are also $\omega$-automata, which are similar to B\"uchi automata except with the acceptance condition given by a set of pairs $(E_i, F_i)$ such that an run is accepted if there is a pair where the run visits $F_i$ infinitely often and does not visit $E_i$ infinitely often.

\section{Synthesis}

Model checking is the art of deciding whether a program meets a specification. Synthesis is the related problem of \emph{constructing} the program to meet a specification. In model checking the actions of the program are decided by the software being checked. A synthesis procedure must instead decide how the controller chooses actions and the ways the environment can react to each decision. In order to model this requirement the controller and environment should be considered to be in an adversarial relationship. Thus the synthesis problem is formulated as a two player game between the reactive program and its environment~\cite{Pnueli89}.

A game is a structure $G = (S, \mathcal{U}, \mathcal{C}, \delta, s_0)$. We consider only two player games and we name those players the \emph{controller} and \emph{environment}. The structure is defined by:

\begin{itemize}
    \item $S$ is a finite set of states,
    \item $\mathcal{U}$ is a finite alphabet of \emph{uncontrollable} actions,
    \item $\mathcal{C}$ is a finite alphabet of \emph{controllable} actions,
    \item $\delta : S \times \mathcal{U} \times \mathcal{C} \to S$ is a transition relation mapping states, uncontrollable actions, and controllable actions to next states,
    \item $s_0 \in S$ is an initial state.
\end{itemize}

Conceptually, the game structure is another finite state automaton where transitions are partially controlled by both players. In each state, the environment chooses an uncontrollable action from $\mathcal{U}$ and the system chooses a controllable action from $\mathcal{C}$. We consider only deterministic games where $\delta(s, u, c, s_1') \land \delta(s, u, c, s_2') \to (s_1' = s_2')$.  We modify the notion of a run to suit games: $(s_0, u_0, c_0), (s_1, u_1, c_1), ... (s_n, u_n, c_n)$ where $\forall i [i \geq 0 \to \delta(s_i, u_i, c_i, s_{i+1})]$. 

In addition to the game structure itself we define a game \emph{objective} $\psi$ given by an LTL formula. We say that a run is \emph{winning} for the controller iff the run satisfies the objective. The game is zero-sum, therefore a run is winning for the environment in the dual case where the objective $\psi$ is not true. For a controller to be correct it must ensure that all choices of the environment lead to runs that are winning for the controller. 

%%%Although $\psi$ is given in LTL we formally define the objective of the game with the \emph{all paths} branching operator: $\forall \mathcal{U} \exists \mathcal{C} A \psi$.

%%%Formally, a run is controller-winning iff $\forall i [i \geq 0 \to \lnot E(s_i)]$ environment-winning iff $\exists i [i \geq 0 \land E(s_i)]$.

A \emph{controller strategy} $\pi^c : \mathcal{S} \times \mathcal{U} \to \mathcal{C}$ is a mapping of states and uncontrollable inputs to controllable actions. $\pi^c$ is a \emph{winning strategy} iff all runs $(s_0, u_0, \pi^c(s_0, u_0)), (s_1, u_1, \pi^c(s_1, u_1)) \dots$ are winning. \emph{Realisability} is the problem of determining the existence of a winning controller strategy and \emph{synthesis} is the problem of constructing it.

An \emph{environment strategy} $\pi^e : \mathcal{S} \to \mathcal{U}$ is a mapping of states to uncontrollable actions. An environment strategy is winning
iff all runs $(s_0, \pi^e(s_0), c_0)$, $(s_1, \pi^e(s_1), c_1) \dots$ are winning for the environment. The existence of a winning environment strategy implies the nonexistence of a winning controller strategy and vice versa.

\subsection{Solving Games}

Reactive synthesis for a game with an LTL objective~\cite{Pnueli89} may be solved via the construction of an equivalent non-deterministic B\"uchi automaton that is subsequently determinised to a deterministic Rabin automaton. Without delving into details, the Rabin automaton is interpreted as a tree-automaton and checked for emptiness. This yields a double exponential time algorithm in the size of the specification.

The double exponential complexity causes a \emph{state explosion}, which led to synthesis being considered infeasible for many years. However, synthesis has been applied in many real world scenarios by restricting the game objective to fragments of LTL. In this thesis we consider \emph{safety games}, or games with objectives of the form $G \phi$ where $\phi$ is a propositional formula only. Informally, a controller in a safety game has the objective to stay within a safe region or avoid error states. Safety games can be solved by drawing on $\mu$-calculus and solving a fixed point calculation~\cite{Asarin95}, which is a much less complex procedure than the above automata theoretic approach. 

Whilst the LTL fragment that is solvable via a safety game is not very expressive, fixed point computations can also be used to solve the much more expressive generalised reactivity fragment of LTL. Safety synthesis can be seen as the first step on the path to more useful yet practical synthesis techniques.


\subsection{Fixed Point Computation}

Modal $\mu$-calculus~\cite{Kozen82} for propositional logic formalises the concept of fixed points. Given a monotone function $f$, a fixed point is a set $X$ such that $f(X) = X$. The least fixpoint operator $\mu$ gives the smallest set $X$ and the greatest fixpoint operator $\nu$ gives the largest. $\mu$-calculus formulas have the following syntax, given with respect to a set of propositions $P$ and a set of variables $V$.

\begin{itemize}
    \item If $p \in P$ then $p$ is a formula
    \item If $p$ is a formula then $\lnot p$ is a formula
    \item If $p$ and $q$ are formulas then $p \land q$ is a formula
    \item If $p$ is a formula and $Z$ is a variable then both $\nu Z . p$ and $\mu Z . p$ are formulas when all occurrences of Z have an even number of negations
    \item If $p$ is a formula and $Z$ is a variable then $\forall Z . p$ is a formula.
    \item Additionally, we introduce some syntactic equivalences:
        \begin{itemize}
            \item $p \lor q \equiv \lnot ( \lnot p \land \lnot q )$
            \item $\exists Z . p \equiv \lnot \forall Z . \lnot p$
        \end{itemize}
\end{itemize}

Given a labelled transition system $(S, F)$ where $S$ is a set of states, and $F : P \to 2^S$ is a mapping of propositions to states with which they hold, we give the semantics of $\mu-calculus$ by a function $\llbracket p \rrbracket$:

\begin{itemize}
    \item $\llbracket p \rrbracket = F(p)$
    \item $\llbracket \lnot p \rrbracket = S \setminus \llbracket p \rrbracket$
    \item $\llbracket p \land q \rrbracket = \llbracket p \rrbracket \cup \llbracket q \rrbracket$
    \item $\llbracket \nu Z . p \rrbracket = \bigcup \{ T \subseteq S | T \subseteq \llbracket p \rrbracket [ Z := T ] \}$ where $\llbracket p \rrbracket [ Z := T ]$ is $\llbracket p \rrbracket$ with $Z$ mapped to $T$.
\end{itemize}

\subsection{Fixed Point Game Solving}

The safety game algorithm is centred on determining sets of states from which the controller can win. The building block of this algorithm is the uncontrollable predecessor ($UPre$), which returns a set of predecessor states from which the environment can force play into a given set. We define this operator for a game structure $G = (S, \mathcal{U}, \mathcal{C}, \delta, s_0)$ as 

$$UPre(X) = \exists u \forall c \exists s \exists x [u \in \mathcal{U} \to (c \in \mathcal{C} \land s \in S \land x \in X \land \delta(s, u, c, x))]$$

For simplicity we describe the algorithm as though playing for the environment. As such we are actually solving the dual to the safety game: a reachability game.  To solve the game we iteratively build a set of states backwards from the error set ($\lnot \phi$) using the uncontrollable predecessor. It is clear that this set will grow monotonically and (since the state space is finite) eventually converge on fixed point. We call this fixed point set the environment's winning set. If this set contains the initial state then the game is unrealisable and the environment's winning strategy is to always play to stay within its winning set. Conversely, if the initial state is outside the environment's winning set then the controller must have a strategy to avoid the error states and the specification is realisable. To give the algorithm in terms of $\mu$-calculus:

$$ SAFE(T) = \nu Y . \lnot UPre( Y \land \lnot T ) $$

\subsection{Symbolic Algorithms}

Model checking suffers from a similar state explosion issue and new approaches were developed in this field to deal with the problem.  In the decisively titled \emph{Symbolic model checking: $10^{20}$ states and beyond}~\cite{Burch90} the authors claim an increase in the size of systems that can be checked from $10^3$--$10^6$ to $10^{20}$. This breakthrough result was achieved via symbolic, as opposed to explicit, representation of the states in the game structure. This result may also be applied to synthesis.

Consider the game structure in the previous sections. Without loss of generality, we may replace the set of states $S$ with a set of boolean variables. A single state is now a valuation to those variables and a set of states may be symbolically represented by a boolean function. In order to combat state explosion a compact representation of boolean functions is required. The standard choice is an ordered binary decision diagram (BDD)~\cite{Bryant86}.

BDDs represent boolean functions as directed acyclic graphs. Each node is contains a variable, each edge represents a decision (true or false) on its parent's variable. One node is designated root and each path through the graph will terminate in one of two sink nodes that represent whether the decisions on that path satisfy the boolean function or not. Isomorphic nodes (where both decisions lead to the same result) may be removed and isomorphic subgraphs may be merged in order to compress the function representation. The ordering of variables in the graph is important to this compressibility. In the worst case the representation is a tree with no removed or merged nodes, which is exponential in the number of variables. Given a boolean function and a variable ordering the corresponding BDD is canonical. Figure~\ref{fig:backgroundBDD} shows two example BDDs that represent the same boolean function with different variable orderings.

\tikzset{>={Latex[width=2.2mm,length=2.5mm]}}
\tikzstyle{one}=[->,blue,solid]
\tikzstyle{zero}=[->,red,dash pattern = on 2pt off 2pt]
\tikzstyle{every node/.style}=[solid,black]
\begin{figure}
    \centering
    \captionsetup{justification=centering}
    \begin{subfigure}[t]{0.5\textwidth}
        \centering
        \begin{tikzpicture}[level distance = 18mm,baseline]
            \node [circle,draw] (a){$a$}
                child {node [circle,draw,left] (b1) {$b$}
                    edge from parent [one]
                }
                child {node [circle,draw,solid,black] (b2) {$b$}
                    child {node [circle,draw,right,solid,black] (c1) {$c$}
                        child {node [circle,draw,solid,black] (d1) {$d$}
                            child {node [draw,left,black] (F) {$\bot$}
                                edge from parent [one]
                            }
                            edge from parent [one]
                        }
                        edge from parent [one]
                    }
                    child {node [circle,draw,right,solid,black] (c2) {$c$}
                        child {node [circle,draw,solid,black] (d2) {$d$}
                            child {node [draw,left,black] (T) {$\top$}
                                edge from parent [one]
                            }
                            edge from parent [one]
                        }
                        edge from parent [zero]
                    }
                    edge from parent [zero]
                }
            ;
            \draw [one,->,bend right] (b1) to (F);
            \draw [zero,->,bend right] (b1) to (T);
            \draw [one,->] (c1) to (T);
            \draw [zero,->] (c2) to (F);
            \draw [zero,->] (d1) to (T);
            \draw [zero,->] (d2) to (F);
        \end{tikzpicture}
    \end{subfigure}%
    \begin{subfigure}[t]{0.5\textwidth}
        \centering
        \begin{tikzpicture}[level distance = 18mm,baseline]
            \node [circle,draw] (a){$a$}
                child {node [circle,draw,solid,black] (d) {$d$}
                    child {node [circle,draw,solid,black] (b) {$b$}
                        child {node [draw,solid,black] (F) {$\bot$}
                            edge from parent [zero]
                        }
                        edge from parent [zero]
                    }
                    child {node [circle,draw,solid,black] (c) {$c$}
                        child {node [draw,solid,black] (T) {$\top$}
                            edge from parent [one]
                        }
                        edge from parent [one]
                    }
                    edge from parent [zero]
                }
            ;
            \draw [one,->] (b) to (T);
            \draw [zero,->] (c) to (F);
            \draw [one,->,bend right] (a) to (b);
        \end{tikzpicture}
    \end{subfigure}
    \caption[Example BDD]{BDDs for $(\lnot a \lor b) \land (a \lor c \lor  \lnot d) \land (b \lor d)$. \\Solid blue transitions are $1$, dashed red transitions are $0$.}
    \label{fig:backgroundBDD}
\end{figure}

Conjunction and disjunction may be performed on BDDs via an algorithm with a running time of $O(n \times m)$ where $n$ and $m$ are the sizes of the two BDDs. The worst case of this algorithm is rarely reached however and in general the operation is efficient. Universal quantification may be performed by constructing the conjunction of the BDD with the quantified variable set one way and the BDD with the variable set the other way. Existential quantification works the same way with disjunction. In this way, the uncontrollable predecessor and winning sets may be efficiently computed and stored via BDDs.

\subsection{Abstraction}

When the state space is truly large, as it can be in many real world systems, symbolic representation is an insufficient optimisation to synthesise the system. Real world systems contain many complex details that may not be relevant to the verification property. Abstraction aims to reduce the level of detail in the system, without sacrificing correctness, so that it may be synthesised. For example, a system may require that a controller write a value to an 8 bit register ($2^8$ possible states). If the specification only refers to the register as being equal to a particular value then the abstraction may reduce this to 1 bit: set to the value, and not set to the value.

An abstraction is a mapping of \emph{concrete} states onto a new, smaller, set of  \emph{abstract} states. Abstractions may be created manually or automatically constructed. A common technique is to approximate an abstraction for a system and refine it during the verification process. Counterexample guided abstraction refinement (CEGAR)~\cite{Clarke00} is a framework in which an approximate abstraction is refined via the analysis of counterexamples to the specification. An upper approximation is used for abstraction so that when the specification holds for the abstraction it also holds for concrete system. However, when a counterexample is found in the abstraction it may not be a concrete counterexample, in which case we call it a \emph{spurious} counterexample. These counterexamples are used for refinement and the procedure begins anew with the refined abstraction.

\section{Boolean Satisfiability}

The ability to prove existentially quantified boolean formulas satisfiable or
unsatisfiable (SAT) is enormously useful for program verification. Significant
research has led to many highly efficient solvers for the SAT problem. Modern
SAT solvers are based on the Davis-Putnam-Logemann-Loveland (DPLL) algorithm
\cite{Davis60, Davis62}. This algorithm is a backtracking search that operates
on the formula given in conjunctive normal form (CNF).

A CNF formula is a set of \emph{clauses} of the form $(l_0 \lor l_1 \lor ...
\lor l_n)$ where each \emph{literal} $l_i$ is a boolean variable or its
negation. We call a clause with only one literal a \emph{unit clause}. We call
a variable \emph{pure} if it appears in only one polarity in the formula. The
DPLL algorithm propagates unit clauses and removes clauses with pure literals
as its first step. Next a value is assigned to a variable and the algorithm recurses to search for a solution with that valuation. If none can be found then a backtracking occurs and the other polarity of the variable is tried. In modern solvers, clause learning is used to share information between different branches of the search tree. The algorithm terminates when the current variable assignment satisfies the formula, or the search space is exhausted.

\subsection{Bounded Model Checking}
\label{sec:boundedmodelchecking}

In the previous section BDDs were discussed as a symbolic representation that compresses boolean functions and efficiently quantifies the function. A CNF representation of a function is not canonical and so does not necessarily suffer from the same state explosion problems as BDDs. Biere et al.~\cite{Biere99} introduced a model checking methodology that takes advantage of CNF as a symbolic representation and utilises a SAT solver to efficiently operate on it. We discussed BDDs in the context of solving games, however the context of this section is model checking of CTL* properties. It suffices to say that BDDs are applicable to this area as well and have similar advantages and disadvantages.

Instead of constructing a set of winning states this technique, called \emph{bounded model checking}, searches for runs of the game. Conceptually the BDD approach is similar to breadth first search and bounded model checking is similar to depth first search. In broad strokes, the new methodology consists of constructing a propositional formula representing the existence of a program trace of a certain length $k$ that violates the specification. The formula is solved by a SAT solver, which returns either SAT: a counterexample to the specification, or UNSAT: there is no counterexample of length $k$. The algorithm executes this process for increasing lengths $k$, which we call the \emph{bound}.

One difficulty of this approach is choosing a maximum bound that is both \emph{sufficient} to verify the program correct and \emph{feasible} to compute the result of the propositional formula. For a finite state automaton, the \emph{diameter} is the minimal length such that every reachable state can by reached by a path of that length or less. The diameter is sufficient for model checking but not always feasible. In addition, computing the diameter itself is an inefficient quantified boolean formula. Despite this difficulty, bounded model checking is useful in many practical cases. In particular the ability to quickly find short counterexamples gives an advantage in cases when a BDD based approach hits state explosion issues.

\subsection{Interpolation}
\label{sec:backgroundInterpolation}

A Craig interpolant, $\mathcal{I}$, is defined with respect to two formulas, $A$ and $B$, that are inconsistent ($A \land B \equiv \bot$) and has the following properties

\begin{itemize}
    \item $A \to \mathcal{I}$
    \item $B \land \mathcal{I} \equiv \bot$
    \item $vars(\mathcal{I}) \subseteq vars(A) \cap vars(B)$ where $vars(X)$ is the set of variables referred to by $X$.
\end{itemize}

Propositional logic interpolants can be efficiently derived from the resolution proof of unsatisfiability of $A$ and $B$. Due to their interesting properties and efficient construction, interpolants have be found to be useful in many areas of model checking~\cite{McMillan05}. In general, interpolants are valuable for their ability to approximate. Intuitively, an interpolant is an approximation of $A$ that captures only the details needed for a proof of unsatisfiability of $A$ and $B$. If the proof represents something important about the system, such as a counterexample to the specification, then the interpolant captures important details.  Interpolation can be used as an alternative to building a winning set in model checking by instead incrementally building an inductive invariant for the system from counterexample refutations. Chapter~\ref{ch:relatedwork} contains a survey of model checking and synthesis methods that exploit this intuition. Interpolation is also central to the algorithm presented in this thesis.

\subsection{Quantified Boolean Formulas}
\label{sec:backgroundQBF}

A quantified boolean formula (QBF) extends satisfiability with the addition of quantifiers. We consider formulas in prenex normal form $Q_1 \hat{x} Q_2 \hat{y} ... F(\hat{x}, \hat{y}, ...)$ where $Q_i \in \{ \exists, \forall \}$, $\hat{x}, \hat{y}, ...$ are sets of boolean variables, and $F$ is a propositional formula over the quantified variables in CNF.

Quantifiers over boolean variables may be \emph{expanded} into propositional formulas like so:

\begin{itemize}
    \item $\exists x F(x) \equiv F(\texttt{true}) \lor F(\texttt{false})$
    \item $\forall x F(x) \equiv F(\texttt{true}) \land F(\texttt{false})$
\end{itemize}

Expansion may be used to construct a SAT problem from QBF but the CNF formula may be exponentially larger than its QBF representation. We will discuss alternative approaches to solving QBF problems in Chapter~\ref{ch:relatedwork}.

A \emph{Skolem function} for variables $\hat{s}$ with respect to a QBF $$\exists \hat{x}_1 \forall \hat{y}_1 ... \exists \hat{x}_i \forall \hat{y}_i \exists \hat{s} Q_1 \hat{z}_1 ... Q_j \hat{z}_j F(\hat{x}_1, \hat{y}_1, ..., \hat{x}_i, \hat{y}_i, \hat{s}, \hat{z}_1, ..., \hat{z}_j)$$ is a function $f : 2^{|\hat{y}_1|} \times ... \times 2^{|\hat{y}_i|} \to 2^{|\hat{s}|}$ such that $$\exists \hat{x}_1 \forall \hat{y}_1 ... \exists \hat{x}_i \forall \hat{y}_i Q_1 \hat{z}_1 ... Q_j \hat{z}_j F(\hat{x}_1, \hat{y}_1, ..., \hat{x}_i, \hat{y}_i, f(\hat{y}_1, ..., \hat{y}_i), ..., \hat{z}_1, ..., \hat{z}_j)$$ is equisatisfiable to the original QBF. In other words, if $\psi$ is a satisfiable QBF, then $f$ assigns a value to $\hat{s}$ for every assignment to universally quantified variables in the prefix such $\psi[\hat{s} / f]$ is also satisfiable. It is possible to reduce a QBF to \emph{Skolem normal form} by substituting all existential variables with a valid Skolem function.


\section{Summary}

In this chapter we have introduced several concepts necessary for an understanding of the central work of this thesis. We briefly summarise some key points here as an aid to the reader.

\begin{itemize}

    \item Temporal logic is the language we use to describe systems when a formalisation of time is necessary to express correctness. The existing body of work on synthesis and model checking is vast and this mathematical foundation of temporal logic provides the common language we use to define particular specialisations. In this thesis we are concerned with safety synthesis, which is formalised as a two player game with a winning condition defined by a subset of linear temporal logic with a single global operator.

    \item Model checking is an approach to automatically verifying the correctness of programs. In this chapter we briefly introduced the problem and two techniques used to solve it. In the next chapter we will expand on some existing work on model checking that is related to the synthesis techniques introduced by this thesis.

    \item Synthesis is a game between a system and its environment. Synthesis games may be solved by constructing a winning region via a fixed point computation of the controllable predecessor operator. In order to make this process scalable states are represented symbolically. Binary decision diagrams, which are graphical representations of boolean formulas, are commonly used as a compact symbolic representation of a set of states.

    \item The algorithm presented in this thesis constructs boolean formulas. Here we have defined the problem of satisfiability for boolean formulas and introduced the tools that solve them. Additionally the algorithm makes use of interpolation of boolean formulas, which can be performed efficiently using the certificate generated by SAT solvers.

\end{itemize}
